{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Random forest"
      ],
      "metadata": {
        "id": "L7TcEgzwQaUj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zmNizE4QSNy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, learning_curve\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df_3 = pd.read_csv(\"TobeBalanced1.csv\")"
      ],
      "metadata": {
        "id": "1IC7vCNrQXgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into features and target\n",
        "X = df_3.drop('Default', axis=1)\n",
        "y = df_3['Default']"
      ],
      "metadata": {
        "id": "pvQjHWqlQXip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply RandomUnderSampler to the entire dataset to handle class imbalance\n",
        "under_sampler = RandomUnderSampler(random_state=42)\n",
        "X_under, y_under = under_sampler.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "-BPRvj24QXki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the class distribution after undersampling\n",
        "print(\"Class distribution after undersampling:\")\n",
        "print(pd.Series(y_under).value_counts())"
      ],
      "metadata": {
        "id": "HVDBJ8cRQXnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split on the undersampled dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.2, random_state=42, stratify=y_under)"
      ],
      "metadata": {
        "id": "gANgjTP7QXpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train RandomForestClassifier with class_weight='balanced'\n",
        "rf_clf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
        "rf_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "AiIUPoaCQXrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions for both train and test sets\n",
        "y_train_pred = rf_clf.predict(X_train)\n",
        "y_test_pred = rf_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "WvCVXzORQXts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test accuracy\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "FLUCdCEHQXxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
        "conf_matrix_test = confusion_matrix(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "YY5iXCncQ8RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot heatmaps for confusion matrix\n",
        "def plot_confusion_matrix_heatmap(conf_matrix, title):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', cbar=False)\n",
        "    plt.title(f'Confusion Matrix - {title}')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "BRRwwhkdQ8Ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot heatmaps for train and test confusion matrices\n",
        "plot_confusion_matrix_heatmap(conf_matrix_train, \"Training Set\")\n",
        "plot_confusion_matrix_heatmap(conf_matrix_test, \"Testing Set\")"
      ],
      "metadata": {
        "id": "uvpYQdVhQ8WD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "classification_rep_train = classification_report(y_train, y_train_pred)\n",
        "classification_rep_test = classification_report(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "WdHceitRQ8Ye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print results\n",
        "print(\"\\nTrain Accuracy:\", train_accuracy)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "print(\"\\nTrain Classification Report:\")\n",
        "print(classification_rep_train)\n",
        "print(\"\\nTest Classification Report:\")\n",
        "print(classification_rep_test)"
      ],
      "metadata": {
        "id": "2xi4eGbCQ8aI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Tuning using RandomizedSearchCV\n",
        "param_distributions = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False],\n",
        "    'class_weight': ['balanced', 'balanced_subsample']\n",
        "}"
      ],
      "metadata": {
        "id": "lCETQa29Q8cG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_clf = RandomForestClassifier(random_state=42)"
      ],
      "metadata": {
        "id": "DZ_lt85iQ8fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RandomizedSearchCV for Hyperparameter tuning\n",
        "random_search = RandomizedSearchCV(estimator=rf_clf, param_distributions=param_distributions, n_iter=20, cv=5, n_jobs=-1, verbose=2, random_state=42)"
      ],
      "metadata": {
        "id": "yEsBlSsKQ8lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with the best parameters\n",
        "random_search.fit(X_train, y_train)\n",
        "best_rf_clf = random_search.best_estimator_"
      ],
      "metadata": {
        "id": "b6KtZJMSSEa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best parameters\n",
        "print(\"Best parameters found: \", random_search.best_params_)"
      ],
      "metadata": {
        "id": "4bfKAXE1SEdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the best model on the undersampled dataset\n",
        "best_rf_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "EBvudqG9SEfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions for both train and test sets\n",
        "y_train_pred = best_rf_clf.predict(X_train)\n",
        "y_test_pred = best_rf_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "yMCcpVf6SEiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test accuracy\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "y8xMIKRVSEkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
        "conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n"
      ],
      "metadata": {
        "id": "tWzrN96lSQrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot heatmaps for the best model's confusion matrices\n",
        "plot_confusion_matrix_heatmap(conf_matrix_train, \"Best Model - Training Set\")\n",
        "plot_confusion_matrix_heatmap(conf_matrix_test, \"Best Model - Testing Set\")"
      ],
      "metadata": {
        "id": "SDinrJx2SQty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "classification_rep_train = classification_report(y_train, y_train_pred)\n",
        "classification_rep_test = classification_report(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "z6xcu_3oSQv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print results for best model\n",
        "print(\"\\nBest Model Train Accuracy:\", train_accuracy)\n",
        "print(\"Best Model Test Accuracy:\", test_accuracy)\n",
        "print(\"\\nBest Model Train Classification Report:\")\n",
        "print(classification_rep_train)\n",
        "print(\"\\nBest Model Test Classification Report:\")\n",
        "print(classification_rep_test)\n"
      ],
      "metadata": {
        "id": "GS302-oNSQx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Learning Curve to detect overfitting/underfitting\n",
        "def plot_learning_curve(estimator, X, y, title=\"Learning Curve\", cv=None, n_jobs=None, train_sizes=np.linspace(0.1, 1.0, 5)):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "\n",
        "    # Compute the learning curve\n",
        "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "\n",
        "    # Calculate mean and standard deviation for train and test scores\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    # Plot learning curve\n",
        "    plt.grid()\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "\n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt"
      ],
      "metadata": {
        "id": "1x2zciIqSQ0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the learning curve for the best RandomForestClassifier\n",
        "plot_learning_curve(best_rf_clf, X_train, y_train, title=\"Random Forest Learning Curve\", cv=5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oPxEMsp8SQ3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model\n",
        "with open('loan_underSample3(RF).pkl', 'wb') as file:\n",
        "    pickle.dump(best_rf_clf, file)\n",
        "\n",
        "print(\"Model saved as 'loan_underSample3(RF).pkl'\")"
      ],
      "metadata": {
        "id": "9KTeCwDjSEno"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}