{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###  LogisticRegression"
      ],
      "metadata": {
        "id": "L7TcEgzwQaUj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import learning_curve\n",
        "import seaborn as sns\n",
        "import pickle"
      ],
      "metadata": {
        "id": "HXNXGDO_e4mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your dataset\n",
        "df_3 = pd.read_csv(\"TobeBalanced1.csv\")"
      ],
      "metadata": {
        "id": "27kcV9k-fmhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into features and target\n",
        "X = df_3.drop('Default', axis=1)\n",
        "y = df_3['Default']"
      ],
      "metadata": {
        "id": "QJUGYfgHfmk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply RandomUnderSampler to handle class imbalance for the whole dataset\n",
        "under_sampler = RandomUnderSampler(random_state=42)\n",
        "X_under, y_under = under_sampler.fit_resample(X, y)"
      ],
      "metadata": {
        "id": "xlwKjA59fmob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the class distribution after undersampling\n",
        "print(\"Class distribution after undersampling:\")\n",
        "print(pd.Series(y_under).value_counts())"
      ],
      "metadata": {
        "id": "IB2-fzBQf2T_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split after undersampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.2, random_state=42, stratify=y_under)"
      ],
      "metadata": {
        "id": "t-sSZ7NKf2WD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and train Logistic Regression\n",
        "log_reg_clf = LogisticRegression(random_state=42, solver='liblinear')\n",
        "log_reg_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "TxD7nAGJf2Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions for both train and test sets\n",
        "y_train_pred = log_reg_clf.predict(X_train)\n",
        "y_test_pred = log_reg_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "JxJN6bCmf2c2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test accuracy\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "k0ctGl3Uf2fI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
        "conf_matrix_test = confusion_matrix(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "vTk8d0Cbf2hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "classification_rep_train = classification_report(y_train, y_train_pred)\n",
        "classification_rep_test = classification_report(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "U9dw0dEWf2j-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print results\n",
        "print(\"\\nTrain Accuracy:\", train_accuracy)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "print(\"\\nTrain Confusion Matrix:\")\n",
        "print(conf_matrix_train)\n",
        "print(\"\\nTest Confusion Matrix:\")\n",
        "print(conf_matrix_test)\n",
        "\n",
        "print(\"\\nTrain Classification Report:\")\n",
        "print(classification_rep_train)\n",
        "print(\"\\nTest Classification Report:\")\n",
        "print(classification_rep_test)"
      ],
      "metadata": {
        "id": "P6nZNxcpf2mv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Tuning using RandomizedSearchCV for Logistic Regression\n",
        "param_distributions = {\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}"
      ],
      "metadata": {
        "id": "zC0c4HaSf2q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log_reg_clf = LogisticRegression(random_state=42, max_iter=1000)"
      ],
      "metadata": {
        "id": "D0BRAeBof2uS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_search = RandomizedSearchCV(estimator=log_reg_clf, param_distributions=param_distributions, cv=5, n_jobs=-1, verbose=2)"
      ],
      "metadata": {
        "id": "bT9pQF4-f23K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model with the best parameters\n",
        "random_search.fit(X_train, y_train)\n",
        "best_log_reg_clf = random_search.best_estimator_"
      ],
      "metadata": {
        "id": "foJVHJ39f25V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best parameters\n",
        "print(\"Best parameters found: \", random_search.best_params_)"
      ],
      "metadata": {
        "id": "0ETV4hXpf28z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the best model on the undersampled dataset\n",
        "best_log_reg_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "OyW2w0O0gj9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions for both train and test sets\n",
        "y_train_pred = best_log_reg_clf.predict(X_train)\n",
        "y_test_pred = best_log_reg_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "8aSo22iFgj_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test accuracy\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "test_accuracy = accuracy_score(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "ebHrBRGEgkCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix\n",
        "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
        "conf_matrix_test = confusion_matrix(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "z2xIiqcsgkEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print results\n",
        "print(\"\\nTrain Accuracy:\", train_accuracy)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "print(\"\\nTrain Confusion Matrix:\")\n",
        "print(conf_matrix_train)\n",
        "print(\"\\nTest Confusion Matrix:\")\n",
        "print(conf_matrix_test)"
      ],
      "metadata": {
        "id": "jyZ3H2htgkGh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification Report\n",
        "classification_rep_train = classification_report(y_train, y_train_pred)\n",
        "classification_rep_test = classification_report(y_test, y_test_pred)"
      ],
      "metadata": {
        "id": "BPPiSBNmgkJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTrain Classification Report:\")\n",
        "print(classification_rep_train)\n",
        "print(\"\\nTest Classification Report:\")\n",
        "print(classification_rep_test)"
      ],
      "metadata": {
        "id": "1PT8SQHRgkhI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to plot confusion matrix as heatmap\n",
        "def plot_confusion_matrix(cm, title='Confusion Matrix', cmap=plt.cm.Blues):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap=cmap, cbar=False, square=True,\n",
        "                xticklabels=['Not Default', 'Default'], yticklabels=['Not Default', 'Default'])\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "OUSH3kqLg8T4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot heatmaps for confusion matrices\n",
        "plot_confusion_matrix(conf_matrix_train, title='Training Confusion Matrix Heatmap')\n",
        "plot_confusion_matrix(conf_matrix_test, title='Test Confusion Matrix Heatmap')"
      ],
      "metadata": {
        "id": "LEpaKY3Yg8W4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Learning Curve to detect overfitting/underfitting\n",
        "def plot_learning_curve(estimator, X, y, title=\"Learning Curve\", cv=None, n_jobs=None, train_sizes=np.linspace(0.1, 1.0, 5)):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "\n",
        "    # Compute the learning curve\n",
        "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "\n",
        "    # Calculate mean and standard deviation for train and test scores\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    # Plot learning curve\n",
        "    plt.grid()\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "0DK1Bg4kg8Zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot the learning curve for the best Logistic Regression model\n",
        "plot_learning_curve(best_log_reg_clf, X_train, y_train, title=\"Logistic Regression Learning Curve\", cv=5)"
      ],
      "metadata": {
        "id": "xVga6jw-g8dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "with open('log_reg_undersampled.pkl', 'wb') as file:\n",
        "    pickle.dump(best_log_reg_clf, file)\n",
        "\n",
        "print(\"Model saved as 'log_reg_undersampled.pkl'\")"
      ],
      "metadata": {
        "id": "NBqexkQvg8nL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}